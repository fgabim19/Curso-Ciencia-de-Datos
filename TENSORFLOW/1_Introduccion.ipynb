{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "578d744a",
   "metadata": {},
   "source": [
    "# Introducción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49eeafda-b081-4e97-b4d5-6cad71798b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-26 18:45:29.066224: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-26 18:45:29.066261: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-26 18:45:29.067649: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-26 18:45:29.074345: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-26 18:45:29.858335: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6beaeefe",
   "metadata": {},
   "source": [
    "TensorFlow proporciona una variedad de funciones para crear nuevos tensores precargados con valores. Por ejemplo, al invocar range(n), podemos crear un vector de valores espaciados uniformemente, comenzando en 0 (incluido) y terminando en n(no incluido). De forma predeterminada, el tamaño del intervalo es 1. A menos que se especifique lo contrario, los nuevos tensores se almacenan en la memoria principal y se designan para el cálculo basado en CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5a6615c-1efa-4484-a261-4990def4e61b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-26 18:45:47.005282: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:274] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    }
   ],
   "source": [
    "x = tf.range(12, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fdffe0",
   "metadata": {},
   "source": [
    "Cada uno de estos valores se llama elemento del tensor. El tensor xcontiene 12 elementos. Podemos inspeccionar el número total de elementos en un tensor mediante la size función."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c27bb0b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=12>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.size(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b763c4",
   "metadata": {},
   "source": [
    "Podemos acceder a la forma de un tensor (la longitud a lo largo de cada eje) inspeccionando su shapeatributo. Debido a que aquí estamos tratando con un vector, shapecontiene solo un elemento y es idéntico en tamaño."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3656b78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([12])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874b7f73",
   "metadata": {},
   "source": [
    "Podemos cambiar la forma de un tensor sin alterar su tamaño o valores, invocando reshape. Por ejemplo, podemos transformar nuestro vector x cuya forma es (12,) en una matriz Xcon forma (3, 4). Este nuevo tensor conserva todos los elementos pero los reconfigura en una matriz. Observe que los elementos de nuestro vector están dispuestos una fila a la vez y por lo tanto .x[3] == X[0, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84156f11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 4), dtype=float32, numpy=\n",
       "array([[ 0.,  1.,  2.,  3.],\n",
       "       [ 4.,  5.,  6.,  7.],\n",
       "       [ 8.,  9., 10., 11.]], dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tf.reshape(x, (3, 4))\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0382061",
   "metadata": {},
   "source": [
    "Tenga en cuenta que especificar cada componente de forma reshapees redundante. Como ya conocemos el tamaño de nuestro tensor, podemos calcular un componente de la forma teniendo en cuenta el resto. Por ejemplo, dado un tensor de tamaño n y forma del objetivo (h, w), lo sabemos w = n / h.\n",
    "Para inferir automáticamente un componente de la forma, podemos colocar un elemento -1 para el componente de la forma que debe inferirse automáticamente. En nuestro caso, en lugar de llamar a x.reshape(3,4), podríamos haber llamado de manera equivalente a x.reshape(3, 4) como x.reshape(-1, 4) o x.reshape(3, -1)\n",
    "\n",
    "Los profesionales a menudo necesitan trabajar con tensores inicializados para contener todos los ceros o unos. Podemos construir un tensor con todos los elementos establecidos en 0 y una forma de (2, 3, 4) mediante la zeros función."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45b660eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3, 4), dtype=float32, numpy=\n",
       "array([[[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]]], dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.zeros((2, 3, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fca6196c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3, 4), dtype=float32, numpy=\n",
       "array([[[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]],\n",
       "\n",
       "       [[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]]], dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.ones((2, 3, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de5ae03",
   "metadata": {},
   "source": [
    "A menudo deseamos muestrear cada elemento de forma aleatoria (e independiente) de una distribución de probabilidad determinada. Por ejemplo, los parámetros de las redes neuronales suelen inicializarse de forma aleatoria. El siguiente fragmento crea un tensor con elementos extraídos de una distribución gaussiana (normal) estándar con media 0 y desviación estándar 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef9990f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 4), dtype=float32, numpy=\n",
       "array([[ 1.5508819 , -0.8880561 ,  1.7165276 , -0.31434473],\n",
       "       [ 0.21946113,  0.4425539 ,  0.2925976 , -0.1179775 ],\n",
       "       [-0.14528398,  1.3569018 ,  0.21928519, -0.52540404]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.normal(shape=[3, 4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0073758d",
   "metadata": {},
   "source": [
    "Finalmente, podemos construir tensores proporcionando los valores exactos para cada elemento proporcionando listas de Python (posiblemente anidadas) que contengan literales numéricos. Aquí, construimos una matriz con una lista de listas, donde la lista más externa corresponde al eje 0 y la lista interna corresponde al eje 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b56a0ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 4), dtype=int32, numpy=\n",
       "array([[2, 1, 4, 3],\n",
       "       [1, 2, 3, 4],\n",
       "       [4, 3, 2, 1]], dtype=int32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant([[2, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456d848f",
   "metadata": {},
   "source": [
    "# 1.1 Indexación y Corte "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0839cdc",
   "metadata": {},
   "source": [
    "Al igual que con las listas de Python, podemos acceder a elementos tensoriales mediante indexación (comenzando con 0). Para acceder a un elemento en función de su posición relativa al final de la lista, podemos utilizar la indexación negativa. Finalmente, podemos acceder a rangos completos de índices mediante cortes (por ejemplo, X [start:stop] ), donde el valor devuelto incluye el primer índice ( start) pero no el último ( stop). Finalmente, cuando sólo se especifica un índice (o segmento) para un $$ K^{th} $$\n",
    "Tensor de orden, se aplica a lo largo del eje 0. Por lo tanto, en el siguiente código, [-1] selecciona la última fila y [1:3]selecciona la segunda y tercera filas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a17b8dbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(4,), dtype=float32, numpy=array([ 8.,  9., 10., 11.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(2, 4), dtype=float32, numpy=\n",
       " array([[ 4.,  5.,  6.,  7.],\n",
       "        [ 8.,  9., 10., 11.]], dtype=float32)>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[-1], X[1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a41b80b",
   "metadata": {},
   "source": [
    "Tensors en TensorFlow son inmutables y no se pueden asignar. Variables en TensorFlow hay contenedores de estado mutables que admiten asignaciones. Tenga en cuenta que los gradientes en TensorFlow no fluyen hacia atrás a través de Variablelas asignaciones.\n",
    "\n",
    "Más allá de asignar un valor al conjunto Variable, podemos escribir elementos de a Variable especificando índices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc39eaf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(3, 4) dtype=float32, numpy=\n",
       "array([[ 0.,  1.,  2.,  3.],\n",
       "       [ 4.,  5.,  9.,  7.],\n",
       "       [ 8.,  9., 10., 11.]], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_var = tf.Variable(X)\n",
    "X_var[1, 2].assign(9)  # se asigna el valor 9 al elemento fila 1, col 2.\n",
    "X_var"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b233920c",
   "metadata": {},
   "source": [
    "Si queremos asignar el mismo valor a varios elementos, aplicamos la indexación en el lado izquierdo de la operación de asignación. Por ejemplo, accede a la primera y segunda filas, donde toma todos los elementos a lo largo del eje 1 (columna). Si bien analizamos la indexación de matrices, esto también funciona para vectores y tensores de más de dos dimensiones.[:2, :]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e98a6f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(3, 4) dtype=float32, numpy=\n",
       "array([[12., 12., 12., 12.],\n",
       "       [12., 12., 12., 12.],\n",
       "       [ 8.,  9., 10., 11.]], dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_var = tf.Variable(X)\n",
    "X_var[:2, :].assign(tf.ones(X_var[:2, :].shape, dtype=tf.float32) * 12)\n",
    "X_var"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fcf075",
   "metadata": {},
   "source": [
    "# 1.2 Operaciones"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
